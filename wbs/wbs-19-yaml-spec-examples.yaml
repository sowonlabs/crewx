# CrewX API Provider YAML Specification Examples
# WBS-19 Phase 2: YAML Specification Definition

# This file demonstrates all features of the API Provider configuration
# Reference: packages/sdk/schema/api-provider-config.json

# =============================================================================
# Section 1: MCP Server Definitions
# =============================================================================

mcp_servers:
  # Filesystem access server
  filesystem:
    command: "npx"
    args:
      - "-y"
      - "@modelcontextprotocol/server-filesystem"
      - "/workspace"
    env:
      NODE_ENV: "production"
      DEBUG: "mcp:*"

  # GitHub integration server
  github:
    command: "npx"
    args:
      - "-y"
      - "@modelcontextprotocol/server-github"
    env:
      GITHUB_TOKEN: "${GITHUB_TOKEN}"  # Environment variable substitution

  # Google Drive server (custom)
  google_drive:
    command: "node"
    args:
      - "./custom-mcp-servers/google-drive-server.js"
    env:
      GOOGLE_CLIENT_ID: "${GOOGLE_CLIENT_ID}"
      GOOGLE_CLIENT_SECRET: "${GOOGLE_CLIENT_SECRET}"

  # Slack integration
  slack:
    command: "npx"
    args:
      - "-y"
      - "@modelcontextprotocol/server-slack"
    env:
      SLACK_BOT_TOKEN: "${SLACK_BOT_TOKEN}"
      SLACK_APP_TOKEN: "${SLACK_APP_TOKEN}"

# =============================================================================
# Section 2: Tool Definitions (Custom Local and HTTP Tools)
# =============================================================================

tools:
  # Example 1: Local tool (in-process execution)
  - name: "calculate"
    description: "Perform mathematical calculations"
    type: "local"
    parameters:
      type: "object"
      properties:
        expression:
          type: "string"
          description: "Mathematical expression to evaluate (e.g., '2 + 2', 'sqrt(16)')"
      required: ["expression"]

  # Example 2: HTTP tool with bearer auth
  - name: "web_search"
    description: "Search the web using custom search API"
    type: "http"
    parameters:
      type: "object"
      properties:
        query:
          type: "string"
          description: "Search query"
        max_results:
          type: "number"
          description: "Maximum number of results"
          default: 10
      required: ["query"]
    http:
      url: "https://api.example.com/search"
      method: "POST"
      headers:
        Content-Type: "application/json"
        User-Agent: "CrewX/1.0"
      auth:
        type: "bearer"
        token: "${SEARCH_API_TOKEN}"
      timeout: 30000

  # Example 3: HTTP tool with API key auth
  - name: "send_email"
    description: "Send email via SendGrid API"
    type: "http"
    parameters:
      type: "object"
      properties:
        to:
          type: "string"
          description: "Recipient email address"
        subject:
          type: "string"
          description: "Email subject"
        body:
          type: "string"
          description: "Email body (plain text)"
      required: ["to", "subject", "body"]
    http:
      url: "https://api.sendgrid.com/v3/mail/send"
      method: "POST"
      headers:
        Content-Type: "application/json"
      auth:
        type: "api_key"
        header: "Authorization"
        key: "Bearer ${SENDGRID_API_KEY}"
      timeout: 15000

  # Example 4: HTTP tool with basic auth
  - name: "deploy_service"
    description: "Deploy service to internal deployment system"
    type: "http"
    parameters:
      type: "object"
      properties:
        service_name:
          type: "string"
          description: "Service name to deploy"
        version:
          type: "string"
          description: "Version tag"
      required: ["service_name", "version"]
    http:
      url: "https://deploy.internal.example.com/api/deploy"
      method: "POST"
      headers:
        Content-Type: "application/json"
      auth:
        type: "basic"
        username: "deploy_user"
        password: "${DEPLOY_PASSWORD}"
      timeout: 60000

# =============================================================================
# Section 3: Agent Definitions (API Provider Examples)
# =============================================================================

agents:
  # -------------------------------------------------------------------------
  # Example 1: OpenAI GPT-4o Agent
  # -------------------------------------------------------------------------
  - id: "openai_assistant"
    name: "OpenAI Assistant"
    role: "assistant"
    description: "General-purpose assistant using OpenAI GPT-4o"
    inline:
      type: "agent"
      provider: "api"                    # API provider (new)
      model: "gpt-4o-mini"                # Model name for OpenAI
      prompt: |
        You are a helpful AI assistant powered by OpenAI GPT-4o.
        You have access to file operations and can execute bash commands.
      api:
        base_url: "https://api.openai.com/v1"
        api_key: "${OPENAI_API_KEY}"
        temperature: 0.7
        max_tokens: 4096
        timeout: 120000
        max_retries: 3
        max_steps: 10                    # Tool calling loop limit
      tools:
        - "read_file"                    # Built-in local tool
        - "write_file"                   # Built-in local tool
        - "bash_command"                 # Built-in local tool

  # -------------------------------------------------------------------------
  # Example 2: LiteLLM Gateway Agent (Multi-Provider)
  # -------------------------------------------------------------------------
  - id: "litellm_agent"
    name: "LiteLLM Agent"
    role: "developer"
    description: "Developer agent using LiteLLM gateway for multi-provider access"
    inline:
      type: "agent"
      provider: "api"
      model: "anthropic/claude-3-5-sonnet-20241022"  # Via LiteLLM
      prompt: |
        You are a senior developer with access to multiple AI models via LiteLLM.
        You can read/write files, execute commands, and access GitHub.
      api:
        base_url: "${LITELLM_BASE_URL}"  # e.g., https://litellm.example.com
        api_key: "${LITELLM_API_KEY}"
        headers:
          X-LiteLLM-Space-ID: "${LITELLM_SPACE_ID}"
        temperature: 0.2                 # More deterministic for code
        max_tokens: 8000
        timeout: 180000                  # 3 minutes
        max_retries: 5
        max_steps: 15
      mcp:
        - "filesystem"                   # MCP server tools
        - "github"                       # MCP server tools
      tools:
        - "read_file"
        - "write_file"
        - "bash_command"
        - "web_search"                   # Custom HTTP tool

  # -------------------------------------------------------------------------
  # Example 3: Custom API Provider with All Features
  # -------------------------------------------------------------------------
  - id: "full_featured_agent"
    name: "Full Featured Agent"
    role: "specialist"
    description: "Demonstrates all API provider features"
    inline:
      type: "agent"
      provider: "api"
      model: "gpt-4o"
      prompt: |
        You are an advanced AI agent with access to:
        - File operations (read/write)
        - Command execution (bash)
        - GitHub integration (via MCP)
        - Google Drive access (via MCP)
        - Web search (custom HTTP tool)
        - Email sending (custom HTTP tool)

        Use tools strategically to accomplish complex tasks.
      api:
        base_url: "https://api.openai.com/v1"
        api_key: "${OPENAI_API_KEY}"
        headers:
          X-Custom-Header: "CrewX Agent"
          X-Request-ID: "${REQUEST_ID}"
        temperature: 0.5
        max_tokens: 16000
        top_p: 0.9
        frequency_penalty: 0.5
        presence_penalty: 0.3
        timeout: 300000                  # 5 minutes
        max_retries: 5
        max_steps: 20
      mcp:
        - "filesystem"
        - "github"
        - "google_drive"
        - "slack"
      tools:
        - "read_file"
        - "write_file"
        - "bash_command"
        - "calculate"                    # Custom local tool
        - "web_search"                   # Custom HTTP tool
        - "send_email"                   # Custom HTTP tool
        - "deploy_service"               # Custom HTTP tool

  # -------------------------------------------------------------------------
  # Example 4: Minimal API Agent (Required Fields Only)
  # -------------------------------------------------------------------------
  - id: "minimal_agent"
    name: "Minimal Agent"
    inline:
      type: "agent"
      provider: "api"
      model: "gpt-4o-mini"
      prompt: "You are a simple AI assistant."
      api:
        base_url: "https://api.openai.com/v1"
        api_key: "${OPENAI_API_KEY}"
      # All other fields use defaults

  # -------------------------------------------------------------------------
  # Example 5: Ollama Local Model (Self-Hosted)
  # -------------------------------------------------------------------------
  - id: "ollama_agent"
    name: "Ollama Local Agent"
    description: "Agent using local Ollama model"
    inline:
      type: "agent"
      provider: "api"
      model: "llama3"                    # Ollama model name
      prompt: "You are a helpful AI assistant running locally."
      api:
        base_url: "http://localhost:11434/v1"  # Ollama OpenAI-compatible endpoint
        # No API key needed for local Ollama
        temperature: 0.7
        max_tokens: 4096
        timeout: 180000
      tools:
        - "read_file"
        - "write_file"

  # -------------------------------------------------------------------------
  # Example 6: OpenRouter Agent (Multi-Provider Marketplace)
  # -------------------------------------------------------------------------
  - id: "openrouter_agent"
    name: "OpenRouter Agent"
    description: "Agent using OpenRouter for model access"
    inline:
      type: "agent"
      provider: "api"
      model: "anthropic/claude-3-5-sonnet-20241022"
      prompt: "You are an AI assistant powered by OpenRouter."
      api:
        base_url: "https://openrouter.ai/api/v1"
        api_key: "${OPENROUTER_API_KEY}"
        headers:
          HTTP-Referer: "https://crewx.ai"
          X-Title: "CrewX Agent"
        temperature: 0.7
        max_tokens: 8000
      tools:
        - "read_file"
        - "write_file"
        - "bash_command"

  # -------------------------------------------------------------------------
  # Example 7: Mixed CLI and API Providers (Compatibility Demo)
  # -------------------------------------------------------------------------

  # CLI Provider (existing - no changes needed)
  - id: "claude_cli_agent"
    name: "Claude CLI Agent"
    role: "developer"
    description: "Traditional CLI-based agent"
    options:
      query: ["--verbose"]
      execute: ["--verbose", "--dangerously-skip-permissions"]
    inline:
      type: "agent"
      provider: "cli/claude"             # CLI provider (existing)
      model: "sonnet"
      prompt: "You are a CLI-based developer agent."

  # API Provider (new - side by side with CLI)
  - id: "claude_api_agent"
    name: "Claude API Agent"
    role: "developer"
    description: "HTTP-based agent using Anthropic API"
    inline:
      type: "agent"
      provider: "api"                    # API provider (new)
      model: "claude-3-5-sonnet-20241022"
      prompt: "You are an API-based developer agent."
      api:
        base_url: "https://api.anthropic.com/v1"
        api_key: "${ANTHROPIC_API_KEY}"
        headers:
          anthropic-version: "2023-06-01"
        temperature: 0.2
        max_tokens: 8000
      tools:
        - "read_file"
        - "write_file"
        - "bash_command"

# =============================================================================
# Environment Variables Reference
# =============================================================================
# The following environment variables are used in this configuration:
#
# OpenAI:
#   OPENAI_API_KEY          - OpenAI API key
#
# Anthropic:
#   ANTHROPIC_API_KEY       - Anthropic API key
#
# LiteLLM:
#   LITELLM_BASE_URL        - LiteLLM gateway base URL
#   LITELLM_API_KEY         - LiteLLM API key
#   LITELLM_SPACE_ID        - LiteLLM space identifier
#
# OpenRouter:
#   OPENROUTER_API_KEY      - OpenRouter API key
#
# MCP Servers:
#   GITHUB_TOKEN            - GitHub personal access token
#   GOOGLE_CLIENT_ID        - Google OAuth client ID
#   GOOGLE_CLIENT_SECRET    - Google OAuth client secret
#   SLACK_BOT_TOKEN         - Slack bot token
#   SLACK_APP_TOKEN         - Slack app token
#
# Custom Tools:
#   SEARCH_API_TOKEN        - Web search API token
#   SENDGRID_API_KEY        - SendGrid API key
#   DEPLOY_PASSWORD         - Deployment system password
#
# Other:
#   REQUEST_ID              - Custom request tracking ID (optional)
#
# =============================================================================
# Notes
# =============================================================================
#
# 1. Environment Variable Substitution:
#    - Use ${VAR_NAME} syntax in YAML strings
#    - CrewX will substitute from process.env at runtime
#    - Missing variables will cause validation errors
#
# 2. Provider Namespace:
#    - cli/    - CLI-based providers (existing)
#    - plugin/ - Plugin providers (existing)
#    - remote/ - Remote MCP providers (existing)
#    - api     - API providers (new)
#
# 3. Tool Precedence:
#    - Built-in tools: read_file, write_file, bash_command (always available)
#    - MCP tools: Loaded from MCP servers (namespace: "server_name:tool_name")
#    - Custom tools: Defined in tools[] section
#
# 4. Model Format:
#    - For OpenAI API: just model name (e.g., "gpt-4o-mini")
#    - For LiteLLM: "provider/model" format (e.g., "anthropic/claude-3-5-sonnet-20241022")
#    - For Ollama: model name (e.g., "llama3")
#
# 5. Backward Compatibility:
#    - All existing CLI/plugin/remote agents continue to work unchanged
#    - API provider is additive, not breaking
#
# =============================================================================
