# WBS-19: API Provider Architecture Design

> **Status**: üü° In Progress
> **Phase**: 1 - Architecture Design
> **Date**: 2025-11-11
> **Author**: @crewx_claude_dev

---

## Table of Contents

1. [Overview](#overview)
2. [Provider Hierarchy Design](#provider-hierarchy-design)
3. [Relationship with BaseAIProvider](#relationship-with-baseaiprovider)
4. [Tool Calling Flow](#tool-calling-flow)
5. [MCP Integration Points](#mcp-integration-points)
6. [Architecture Diagram](#architecture-diagram)
7. [Design Decisions](#design-decisions)

---

## Overview

### Goals

The API Provider implementation adds HTTP-based AI providers to CrewX, enabling:
1. **LiteLLM Gateway Support**: Connect to any LLM via OpenAI-compatible API
2. **Tool Calling**: Integrate Vercel AI SDK's tool calling system
3. **MCP Integration**: Connect Model Context Protocol servers for extended tools
4. **Server Environment**: Enable AI agents in server/cloud environments (vs CLI-only)

### Key Technologies

- **Vercel AI SDK** (`ai`, `@ai-sdk/openai`, `@ai-sdk/openai-compatible`)
- **Zod**: Schema validation for tools
- **MCP SDK**: `@modelcontextprotocol/sdk` for MCP integration
- **SowonFlow Patterns**: YAML spec inspiration from SowonFlow project

---

## Provider Hierarchy Design

### 1. Class Structure

```
AIProvider (interface)
‚îú‚îÄ‚îÄ BaseAIProvider (abstract class - CLI-based)
‚îÇ   ‚îú‚îÄ‚îÄ ClaudeProvider (cli/claude)
‚îÇ   ‚îú‚îÄ‚îÄ GeminiProvider (cli/gemini)
‚îÇ   ‚îú‚îÄ‚îÄ CopilotProvider (cli/copilot)
‚îÇ   ‚îî‚îÄ‚îÄ CodexProvider (cli/codex)
‚îÇ
‚îî‚îÄ‚îÄ BaseAPIProvider (abstract class - HTTP-based) ‚Üê NEW
    ‚îî‚îÄ‚îÄ VercelAIProvider (concrete class) ‚Üê NEW
```

### 2. BaseAPIProvider (Abstract Class)

**Purpose**: Foundation for HTTP-based AI providers using Vercel AI SDK

**Core Responsibilities**:
- Implement `AIProvider` interface (`query`, `execute`, `isAvailable`, `getToolPath`)
- Manage Vercel AI SDK `generateText` / `streamText` calls
- Handle tool initialization and conversion (Local + MCP + HTTP)
- Provider HTTP client configuration (base URL, headers, auth)
- Error handling and retry logic

**Key Methods**:
```typescript
abstract class BaseAPIProvider implements AIProvider {
  // Required AIProvider interface
  abstract readonly name: string;
  abstract isAvailable(): Promise<boolean>;
  abstract query(prompt: string, options?: AIQueryOptions): Promise<AIResponse>;
  abstract execute(prompt: string, options?: AIQueryOptions): Promise<AIResponse>;
  abstract getToolPath(): Promise<string | null>;

  // API Provider specific
  protected abstract initializeModel(): LanguageModel;
  protected abstract initializeTools(): Promise<CoreTool[]>;
  protected convertToolsToVercel(tools: ToolDefinition[]): CoreTool[];
  protected executeToolCall(toolName: string, input: any): Promise<any>;
}
```

### 3. VercelAIProvider (Concrete Class)

**Purpose**: Concrete implementation using Vercel AI SDK's OpenAI-compatible provider

**Configuration**:
```typescript
interface VercelAIProviderConfig {
  name: string;              // e.g., "api/litellm"
  model: string;             // e.g., "gpt-4o-mini"
  baseUrl: string;           // e.g., "https://api.openai.com/v1"
  apiKey: string;            // API authentication
  headers?: Record<string, string>;  // Custom headers
  timeout?: number;          // Request timeout (ms)
  maxTokens?: number;        // Max response tokens
  temperature?: number;      // 0.0 - 2.0
  tools?: ToolDefinition[];  // Local tools
  mcpServers?: MCPServerConfig[];  // MCP servers
}
```

**Example Instantiation**:
```typescript
const provider = new VercelAIProvider({
  name: "api/litellm",
  model: "gpt-4o-mini",
  baseUrl: process.env.LITELLM_BASE_URL,
  apiKey: process.env.LITELLM_API_KEY,
  tools: [readFileTool, writeFileTool, bashTool],
  mcpServers: [filesystemMCP, githubMCP]
});
```

---

## Relationship with BaseAIProvider

### Design Decision: Parallel Hierarchies

**Why NOT Inherit from BaseAIProvider?**

1. **Different Execution Model**:
   - `BaseAIProvider`: Spawns CLI processes (`child_process.spawn`)
   - `BaseAPIProvider`: Makes HTTP requests (`fetch` / Vercel SDK)

2. **Incompatible Methods**:
   - `BaseAIProvider` has CLI-specific methods: `getCliCommand()`, `getDefaultArgs()`, `getExecuteArgs()`
   - These are meaningless for HTTP providers

3. **Tool Handling Difference**:
   - `BaseAIProvider`: Tools executed via CLI tool system (external)
   - `BaseAPIProvider`: Tools executed in-process via Vercel SDK

4. **Code Clarity**:
   - Parallel hierarchies avoid "N/A methods" and forced abstractions
   - Each provider type has methods relevant to its execution model

### Shared Interface: `AIProvider`

Both hierarchies implement the **same interface**:

```typescript
export interface AIProvider {
  readonly name: string;
  isAvailable(): Promise<boolean>;
  query(prompt: string, options?: AIQueryOptions): Promise<AIResponse>;
  execute(prompt: string, options?: AIQueryOptions): Promise<AIResponse>;
  getToolPath(): Promise<string | null>;
}
```

**Benefits**:
- ‚úÖ Type compatibility: CLI and API providers are interchangeable
- ‚úÖ Factory pattern: `DynamicProviderFactory` can create either type
- ‚úÖ Agent runtime: `AgentRuntime` works with any `AIProvider`
- ‚úÖ Clean separation: No forced inheritance of irrelevant methods

### Namespace Convention

**CLI Providers**: `cli/{id}` (e.g., `cli/claude`, `cli/gemini`)
**API Providers**: `api/{id}` (e.g., `api/litellm`, `api/openai`)
**Plugin Providers**: `plugin/{id}` (e.g., `plugin/crush`)
**Remote Providers**: `remote/{id}` (e.g., `remote/agent1`)

---

## Tool Calling Flow

### 1. Tool Types

| Type | Description | Execution | Example |
|------|-------------|-----------|---------|
| **Local Tools** | In-process functions | JavaScript/TypeScript | `read_file`, `write_file`, `bash_command` |
| **MCP Tools** | From MCP servers | MCP protocol | `filesystem:read`, `github:create_pr` |
| **HTTP Tools** | Custom HTTP endpoints | HTTP POST | `custom_api:search` |

### 2. Tool Calling Pipeline

```
User Query
  ‚Üì
AgentRuntime.query()
  ‚Üì
BaseAPIProvider.query()
  ‚Üì
generateText({
  model: languageModel,
  prompt: userPrompt,
  tools: [
    ...localTools,      // read_file, write_file, bash_command
    ...mcpTools,        // From MCP servers
    ...httpTools        // Custom HTTP tools
  ],
  maxSteps: 10           // Tool calling loop limit
})
  ‚Üì
Tool Execution Loop (Vercel SDK handles automatically)
  ‚îú‚îÄ AI decides to use tool
  ‚îú‚îÄ Vercel SDK calls tool.execute(input)
  ‚îÇ   ‚Üì
  ‚îÇ   BaseAPIProvider.executeToolCall(toolName, input)
  ‚îÇ     ‚îú‚îÄ Local: Call in-process function
  ‚îÇ     ‚îú‚îÄ MCP: Forward to MCP client
  ‚îÇ     ‚îî‚îÄ HTTP: POST to custom endpoint
  ‚îú‚îÄ Tool returns result
  ‚îî‚îÄ AI continues with tool result
  ‚Üì
Final Response
```

### 3. Local Tools Implementation

**Built-in Tools**:

```typescript
// packages/sdk/src/core/tools/local-tool-handler.ts
export class LocalToolHandler {
  // File operations
  async readFile(path: string): Promise<string> { ... }
  async writeFile(path: string, content: string): Promise<void> { ... }

  // Command execution
  async bashCommand(command: string): Promise<string> { ... }

  // Convert to Vercel tools
  toVercelTools(): CoreTool[] {
    return [
      tool({
        name: 'read_file',
        description: 'Read file contents from filesystem',
        parameters: z.object({
          path: z.string().describe('File path to read'),
        }),
        execute: async ({ path }) => this.readFile(path),
      }),
      // ... other tools
    ];
  }
}
```

### 4. Tool Schema Conversion

**JSON Schema ‚Üí Zod Schema**:

```typescript
// Convert tool definition to Vercel CoreTool
function convertToolToVercel(toolDef: ToolDefinition): CoreTool {
  // Convert JSON Schema parameters to Zod schema
  const zodSchema = jsonSchemaToZod(toolDef.parameters);

  return tool({
    name: toolDef.name,
    description: toolDef.description,
    parameters: zodSchema,
    execute: async (input) => {
      // Dispatch to appropriate handler
      if (toolDef.type === 'local') {
        return localToolHandler.execute(toolDef.name, input);
      } else if (toolDef.type === 'mcp') {
        return mcpClient.executeTool(toolDef.server, toolDef.name, input);
      } else if (toolDef.type === 'http') {
        return httpToolHandler.execute(toolDef.url, input);
      }
    },
  });
}
```

---

## MCP Integration Points

### 1. MCP Architecture

```
BaseAPIProvider
  ‚Üì
initializeTools()
  ‚îú‚îÄ Local Tools (LocalToolHandler)
  ‚îÇ   ‚îî‚îÄ read_file, write_file, bash_command
  ‚îÇ
  ‚îú‚îÄ MCP Tools (MCPClient)
  ‚îÇ   ‚îú‚îÄ Connect to MCP servers
  ‚îÇ   ‚îú‚îÄ List available tools
  ‚îÇ   ‚îî‚îÄ Convert MCP tools ‚Üí Vercel tools
  ‚îÇ
  ‚îî‚îÄ HTTP Tools (HTTPToolHandler)
      ‚îî‚îÄ Custom API endpoints
```

### 2. MCPClient Class

**Purpose**: Manage MCP server connections and tool discovery

```typescript
// packages/sdk/src/core/mcp/mcp-client.ts
export class MCPClient {
  private connections: Map<string, Client>;

  // Connect to MCP server
  async connect(config: MCPServerConfig): Promise<void> {
    const transport = new StdioClientTransport({
      command: config.command,
      args: config.args,
      env: config.env,
    });

    const client = new Client({
      name: `crewx-client-${config.name}`,
      version: '1.0.0',
    }, {
      capabilities: {
        tools: {},
      },
    });

    await client.connect(transport);
    this.connections.set(config.name, client);
  }

  // Get all tools from a server
  async getTools(serverName: string): Promise<MCPTool[]> {
    const client = this.connections.get(serverName);
    if (!client) throw new Error(`MCP server ${serverName} not connected`);

    const { tools } = await client.listTools();
    return tools;
  }

  // Execute MCP tool
  async executeTool(serverName: string, toolName: string, input: any): Promise<any> {
    const client = this.connections.get(serverName);
    if (!client) throw new Error(`MCP server ${serverName} not connected`);

    const result = await client.callTool({ name: toolName, arguments: input });
    return result.content;
  }

  // Convert MCP tools to Vercel tools
  toVercelTools(serverName: string, mcpTools: MCPTool[]): CoreTool[] {
    return mcpTools.map(mcpTool =>
      tool({
        name: `${serverName}:${mcpTool.name}`,
        description: mcpTool.description,
        parameters: jsonSchemaToZod(mcpTool.inputSchema),
        execute: async (input) =>
          this.executeTool(serverName, mcpTool.name, input),
      })
    );
  }
}
```

### 3. MCP Server Lifecycle

```
Agent Initialization
  ‚Üì
BaseAPIProvider constructor
  ‚Üì
initializeTools() called
  ‚Üì
For each MCP server in config:
  ‚îú‚îÄ MCPClient.connect(serverConfig)
  ‚îÇ   ‚îî‚îÄ Spawn MCP server process
  ‚îÇ   ‚îî‚îÄ Establish stdio transport
  ‚îÇ
  ‚îú‚îÄ MCPClient.getTools(serverName)
  ‚îÇ   ‚îî‚îÄ List available tools from server
  ‚îÇ
  ‚îî‚îÄ MCPClient.toVercelTools(serverName, tools)
      ‚îî‚îÄ Convert to Vercel CoreTool format
  ‚Üì
All tools ready for generateText()
```

### 4. Error Handling

**MCP Server Failures**:
- **Connection Timeout**: Retry 3 times with exponential backoff
- **Server Crash**: Log error, continue with remaining tools
- **Tool Execution Error**: Return error to AI, let it retry or adapt

```typescript
async initializeTools(): Promise<CoreTool[]> {
  const allTools: CoreTool[] = [];

  // 1. Local tools (always available)
  allTools.push(...this.localToolHandler.toVercelTools());

  // 2. MCP tools (best effort)
  for (const serverConfig of this.config.mcpServers || []) {
    try {
      await this.mcpClient.connect(serverConfig);
      const mcpTools = await this.mcpClient.getTools(serverConfig.name);
      allTools.push(...this.mcpClient.toVercelTools(serverConfig.name, mcpTools));
      this.logger.log(`‚úÖ Connected to MCP server: ${serverConfig.name} (${mcpTools.length} tools)`);
    } catch (error) {
      this.logger.error(`‚ùå Failed to connect to MCP server ${serverConfig.name}:`, error);
      // Continue with other servers
    }
  }

  // 3. HTTP tools
  allTools.push(...this.httpToolHandler.toVercelTools(this.config.tools || []));

  return allTools;
}
```

---

## Architecture Diagram

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         CrewX Agent System                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                           ‚îÇ
                    ‚ñº                           ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   CLI Agent Runtime   ‚îÇ   ‚îÇ   API Agent Runtime    ‚îÇ
        ‚îÇ                       ‚îÇ   ‚îÇ                        ‚îÇ
        ‚îÇ  Uses: BaseAIProvider ‚îÇ   ‚îÇ  Uses: BaseAPIProvider ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                           ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                     ‚îÇ     ‚îÇ                     ‚îÇ
         ‚ñº                     ‚ñº     ‚ñº                     ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Claude ‚îÇ         ‚îÇ Gemini ‚îÇ ‚îÇ VercelAI    ‚îÇ   ‚îÇ Custom   ‚îÇ
    ‚îÇProvider‚îÇ         ‚îÇProvider‚îÇ ‚îÇProvider     ‚îÇ   ‚îÇAPI       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇProvider  ‚îÇ
         ‚îÇ                  ‚îÇ           ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ spawn CLI        ‚îÇ           ‚îÇ HTTP API        ‚îÇ
         ‚ñº                  ‚ñº           ‚ñº                 ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ claude ‚îÇ         ‚îÇ gemini ‚îÇ ‚îÇ   Vercel AI SDK          ‚îÇ
    ‚îÇ  CLI   ‚îÇ         ‚îÇ  CLI   ‚îÇ ‚îÇ   + LiteLLM Gateway      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### BaseAPIProvider Internal Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        BaseAPIProvider                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                     Configuration                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - model, baseUrl, apiKey, headers                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - temperature, maxTokens, timeout                          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                  Tool Initialization                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Local Tools    ‚îÇ  ‚îÇ   MCP Tools     ‚îÇ  ‚îÇ  HTTP Tools  ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ              ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - read_file    ‚îÇ  ‚îÇ MCPClient       ‚îÇ  ‚îÇ HTTPHandler  ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - write_file   ‚îÇ  ‚îÇ  ‚îú‚îÄ Connect     ‚îÇ  ‚îÇ  ‚îú‚îÄ POST     ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ - bash_command ‚îÇ  ‚îÇ  ‚îú‚îÄ List Tools  ‚îÇ  ‚îÇ  ‚îú‚îÄ Auth     ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ  ‚îî‚îÄ Execute     ‚îÇ  ‚îÇ  ‚îî‚îÄ Parse    ‚îÇ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                    ‚îÇ                    ‚îÇ        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                              ‚îÇ                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                    Convert to CoreTool[]                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îò ‚îÇ
‚îÇ                                 ‚îÇ                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              Vercel AI SDK Integration                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   generateText({                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     model: LanguageModel,                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     prompt: string,                                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     tools: CoreTool[],  ‚Üê All tools merged               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     maxSteps: 10                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   })                                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Tool Execution Loop (automatic):                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     1. AI decides to use tool                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     2. Tool.execute(input) called                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     3. Result returned to AI                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     4. AI continues or uses another tool                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     5. Repeat until final answer                         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                 ‚îÇ                               ‚îÇ
‚îÇ                                 ‚ñº                               ‚îÇ
‚îÇ                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                         ‚îÇ  AIResponse   ‚îÇ                       ‚îÇ
‚îÇ                         ‚îÇ  - content    ‚îÇ                       ‚îÇ
‚îÇ                         ‚îÇ  - success    ‚îÇ                       ‚îÇ
‚îÇ                         ‚îÇ  - toolCall   ‚îÇ                       ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tool Calling Sequence Diagram

```
User ‚Üí AgentRuntime ‚Üí BaseAPIProvider ‚Üí Vercel SDK ‚Üí Tools
  ‚îÇ                                         ‚îÇ
  ‚îÇ query("Create file.txt")                ‚îÇ
  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ                        generateText()   ‚îÇ
  ‚îÇ                        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ                                    Tool Loop:
  ‚îÇ                                         ‚îÇ
  ‚îÇ                                  1. AI: "I'll use write_file"
  ‚îÇ                                         ‚îÇ
  ‚îÇ                                  2. execute(write_file, {...})
  ‚îÇ                        <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ           executeToolCall()             ‚îÇ
  ‚îÇ       <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ  LocalToolHandler.writeFile()           ‚îÇ
  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>                  ‚îÇ
  ‚îÇ          OK                             ‚îÇ
  ‚îÇ  <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                  ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ           Tool Result                   ‚îÇ
  ‚îÇ       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ                                  3. AI: "File created successfully"
  ‚îÇ                                         ‚îÇ
  ‚îÇ                        Final Response   ‚îÇ
  ‚îÇ                        <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
  ‚îÇ                                         ‚îÇ
  ‚îÇ AIResponse{ content: "File created" }   ‚îÇ
  ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
```

---

## Design Decisions

### 1. Why Vercel AI SDK?

**Alternatives Considered**:
- LangChain.js
- LlamaIndex.ts
- Raw OpenAI SDK

**Decision**: Vercel AI SDK

**Rationale**:
- ‚úÖ **Simple API**: `generateText()` handles tool calling loop automatically
- ‚úÖ **OpenAI Compatible**: Works with any OpenAI-compatible API (LiteLLM, vLLM, etc.)
- ‚úÖ **Type Safety**: Full TypeScript support with Zod integration
- ‚úÖ **Streaming**: Built-in streaming support via `streamText()`
- ‚úÖ **Production Ready**: Battle-tested in Vercel products
- ‚úÖ **Lightweight**: Smaller than LangChain, faster startup

### 2. Why Parallel Hierarchies (Not Inheritance)?

**Alternatives Considered**:
- Option A: `BaseAPIProvider extends BaseAIProvider`
- Option B: Single `UnifiedProvider` for both CLI and API
- **Option C (Chosen)**: Parallel hierarchies, shared `AIProvider` interface

**Rationale**:
- ‚úÖ **Clean Separation**: No "N/A" methods or forced abstractions
- ‚úÖ **Clear Intent**: CLI vs API execution models are fundamentally different
- ‚úÖ **Maintainability**: Changes to CLI providers don't affect API providers
- ‚úÖ **Type Safety**: Interface ensures compatibility, not inheritance

### 3. Why Local + MCP + HTTP Tools?

**Rationale**:
- **Local Tools**: Fast, no external dependencies, always available
- **MCP Tools**: Extensibility, ecosystem compatibility, standard protocol
- **HTTP Tools**: Custom integrations, existing APIs, flexibility

**Best of All Worlds**:
- Simple tasks ‚Üí Local tools (fast, reliable)
- Standard integrations ‚Üí MCP tools (filesystem, GitHub, Slack)
- Custom needs ‚Üí HTTP tools (internal APIs, third-party services)

### 4. Why JSON Schema ‚Üí Zod Conversion?

**Rationale**:
- CrewX YAML uses JSON Schema for tool parameters (standard, human-readable)
- Vercel SDK requires Zod schemas (runtime validation, type inference)
- Conversion layer bridges the two worlds seamlessly

### 5. Why maxSteps Limit?

**Rationale**:
- **Safety**: Prevents infinite tool calling loops
- **Cost Control**: Limits token usage for runaway agents
- **UX**: Users get response within reasonable time

**Default**: `maxSteps: 10` (configurable per agent)

---

## Next Steps

### Phase 2: YAML Specification (WBS-19 Phase 2)

1. ‚úÖ Analyze SowonFlow YAML spec (completed)
2. Define `agents[].inline` schema extensions for API providers
3. Define `mcp_servers` section
4. Define `tools` section
5. Generate JSON Schema for validation

### Phase 3: TypeScript Type System (WBS-19 Phase 3)

1. Create `packages/sdk/src/types/api-provider.types.ts`
2. Define Zod schemas for validation
3. Ensure SowonFlow compatibility

### Phase 4: Implementation (WBS-20+)

1. Implement `BaseAPIProvider` class
2. Implement `VercelAIProvider` class
3. Implement `LocalToolHandler`
4. Implement `MCPClient`
5. Implement tool conversion logic

---

## References

- [Vercel AI SDK Documentation](https://sdk.vercel.ai/docs)
- [SowonFlow Production Code](file:///Users/doha/git/sowonai/packages/sowonflow)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [WBS-18 Provider Integration](wbs-18-agent-provider-integration.md)
- [CrewX Provider Architecture](../packages/sdk/src/core/providers/)
