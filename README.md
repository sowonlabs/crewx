# SowonAI CrewX

> Bring Your Own AI(BYOA) team in Slack/IDE(MCP) with your existing subscriptions
Transform Claude, Gemini, Codex and Copilot into a collaborative development team. No extra costs‚Äîjust your existing AI subscriptions working together.

![CrewX usage overview](docs/diagram1.svg)

## Why CrewX?

### **Slack Team Collaboration** - Your AI Team in Slack
Bring AI agents directly into your team's workspace:
- **Team-wide AI access** - Everyone benefits from AI expertise in Slack channels
- **Thread-based context** - Maintains conversation history automatically
- **Multi-agent collaboration** - `@claude`, `@gemini`, `@copilot` work together in real-time
- **Natural integration** - Works like chatting with team members
- **Shared knowledge** - Team learns from AI interactions, not isolated sessions

### **Remote Agents** - Distributed AI Teams (Experimental)
Connect and orchestrate CrewX instances across projects and servers:
- **Cross-project experts** - Frontend dev asks backend team's API specialist agent
- **Team collaboration** - Each team builds their own agents, entire org can use them
- **Expert knowledge sharing** - Ask senior's code review agent, security team's audit agent anytime
- **Separate but connected** - Each project keeps its own context, collaborate when needed

```yaml
# Access another project's specialized agents
providers:
  - id: backend_project
    type: remote
    location: "file:///workspace/backend-api/crewx.yaml"
    external_agent_id: "api_expert"

# Use their expertise in your project
crewx query "@api_expert design user authentication API"
crewx execute "@api_expert implement OAuth flow"
```

### **Plugin Provider System** - Universal AI Integration
Transform any CLI tool or AI service into an agent:
- **Bring Your Own AI** - OpenAI, Anthropic, Ollama, LiteLLM, or any AI service
- **Bring Your Own Tools** - jq, curl, ffmpeg, or any CLI tool becomes an agent
- **Bring Your Own Framework** - Integrate LangChain, CrewAI, AutoGPT seamlessly
- **No coding required** - Simple YAML configuration
- **Mix and match** - Combine different AI services in one workflow

```yaml
# Example: Add any AI service as a plugin
providers:
  - id: ollama
    type: plugin
    cli_command: ollama
    default_model: "llama3"
    query_args: ["run", "{model}"]
    prompt_in_args: false

agents:
  - id: "local_llama"
    provider: "plugin/ollama"
```

### **Claude Skills Compatible** - Reusable AI Expertise
Share and reuse specialized AI capabilities using Claude Code skills format:
- **100% Claude Code compatible** - Use existing Claude skills without modification
- **Agent enhancement** - Add specialized capabilities to any agent
- **Progressive disclosure** - Skills load metadata first, content on-demand
- **Cross-agent sharing** - One skill, multiple agents
- **Simple YAML + Markdown** - Easy to create and maintain

```yaml
# Enable skills for your agents
skills:
  paths:
    - ./skills                    # Custom skill directories
  include:
    - hello                       # Specific skills to load
    - code-reviewer
    - api-designer

agents:
  - id: "senior_dev"
    provider: "cli/claude"
    skills:
      include:
        - code-reviewer           # Agent-specific skills
        - api-designer
    inline:
      prompt: |
        You are a senior developer with specialized skills.
```

**Create a skill** in `skills/hello/SKILL.md`:
```markdown
---
name: hello
description: Friendly greeting skill
version: 0.0.1
---

# Hello Skill

Use this skill to provide friendly greetings.

## Capabilities
- Generate personalized greetings
- Demonstrate skill system functionality
```

**Test across providers**:
```bash
# Test with different AI providers
CREWX_CONFIG=crewx.skills.yaml crewx query "@skill_tester_claude test hello skill"
CREWX_CONFIG=crewx.skills.yaml crewx query "@skill_tester_gemini test hello skill"
```

üëâ **[Skills Documentation ‚Üí](./docs/skills.md)** | **[Example Skills ‚Üí](./skills/)**

### **Project Templates** - Quick Project Bootstrap
Start new projects with pre-configured templates:
- **Ready-to-use setups** - WBS automation, development workflows, deployment configs
- **Git-based templates** - Templates stored in GitHub repository
- **Simple commands** - List, preview, and initialize templates instantly
- **Customizable** - Edit downloaded templates to fit your needs

```bash
# List available templates
crewx template list

# View template details
crewx template show wbs-automation

# Initialize template in current directory
crewx template init wbs-automation
```

**Available templates:**
- `wbs-automation` - **WBS task tracking with coordinator agent** ‚≠ê **30-min timeboxing built-in**
- `development` - Development team setup with code review agents
- `deployment` - CI/CD deployment automation
- More templates coming soon!

üëâ **[Project Templates Documentation ‚Üí](./docs/project-templates.md)**

### **WBS Skill - Work Breakdown Structure Automation**
Intelligent task decomposition and project coordination using the Work Breakdown Structure methodology:

- **30-Minute Timeboxing** - Each task is optimally sized for AI work sessions
- **AI Coordinator Pattern** - Coordinator agents break down complex tasks into manageable jobs
- **Worker Agent Execution** - Specialized agents execute specific jobs in sequence
- **State Management** - Track project progress and job completion automatically
- **Parallel & Sequential Execution** - Optimize workflow with intelligent job scheduling

```yaml
# Configure a WBS coordinator agent
agents:
  - id: "project_coordinator"
    name: "Project Coordinator"
    provider: ["cli/claude", "cli/gemini", "cli/copilot"]
    skills:
      include:
        - wbs  # Enable WBS task decomposition skill
    inline:
      type: "agent"
      prompt: |
        You are a project coordinator. Use the WBS skill to decompose 
        complex tasks into 30-minute jobs and assign them to appropriate worker agents.

# Worker agents for task execution
  - id: "frontend_dev"
    name: "Frontend Developer"
    inline:
      type: "agent"
      provider: "cli/copilot"
      prompt: "You specialize in React and frontend development."

  - id: "backend_dev"
    name: "Backend Developer"
    inline:
      type: "agent"
      provider: "cli/claude"
      prompt: "You specialize in API design and backend implementation."

  - id: "tester"
    name: "QA Tester"
    inline:
      type: "agent"
      provider: "cli/gemini"
      prompt: "You specialize in testing and quality assurance."
```

#### 30-Minute Timeboxing Principle

WBS follows strict timeboxing to optimize AI agent performance:

| Category | Duration | Description |
|----------|----------|-------------|
| **Minimum** | 15 min | Below this ‚Üí combine with related tasks |
| **Optimal** | 25-30 min | Target duration for focused AI work |
| **Maximum** | 45 min | Above this ‚Üí re-decompose into smaller jobs |

**Why 30-minute sessions?**
- **Context Management** - Prevents "Lost in the Middle" and context rot in LLMs
- **Focus Optimization** - Matches human Pomodoro technique for sustained attention
- **Quality Assurance** - Smaller tasks yield more accurate results
- **Parallelization** - Enables efficient multi-agent coordination

#### Workflow Example

```bash
# 1. Coordinator analyzes and decomposes the task
crewx query "@project_coordinator Plan and implement user authentication system"

# 2. Coordinator creates WBS jobs:
# - Job 1: Design auth architecture (@backend_dev, 30 min)
# - Job 2: Implement login API (@backend_dev, 30 min)  
# - Job 3: Create login UI components (@frontend_dev, 30 min)
# - Job 4: Write authentication tests (@tester, 30 min)
# - Job 5: Integrate and verify system (@project_coordinator, 30 min)

# 3. Execute jobs sequentially or in parallel
crewx execute "@backend_dev implement OAuth2 authentication flow"
crewx execute "@frontend_dev create React login components"

# 4. Monitor project status
crewx query "@project_coordinator Show WBS project status"
```

#### Project Status Management

```bash
# List all WBS projects
node skills/wbs/wbs.js list

# Show detailed project status
node skills/wbs/wbs.js status <project-id>

# Execute next pending job automatically
node skills/wbs/wbs.js job next <project-id>

# Run all pending jobs sequentially
node skills/wbs/wbs.js job run <project-id>
```

#### Job Status Flow

```
pending ‚Üí running ‚Üí completed
                  ‚Üí failed (retry available)
```

**Key Design Principles:**
1. **AI Makes Intelligent Decisions** - Complexity analysis and task decomposition
2. **Code Handles State Only** - WBS system manages job tracking and execution
3. **30-Minute Sessions** - Optimal duration for AI agent focus and accuracy
4. **Progressive Improvement** - Start simple, iterate based on results

üëâ **[WBS Skill Details ‚Üí](./skills/wbs/SKILL.md)** | **[WBS Skill Examples ‚Üí](./wbs/)**

### **WBS Skill - Work Breakdown Structure Automation**
Intelligent task decomposition and project coordination using the Work Breakdown Structure methodology:

- **30-Minute Timeboxing** - Each task is optimally sized for AI work sessions
- **AI Coordinator Pattern** - Coordinator agents break down complex tasks into manageable jobs
- **Worker Agent Execution** - Specialized agents execute specific jobs in sequence
- **State Management** - Track project progress and job completion automatically
- **Parallel & Sequential Execution** - Optimize workflow with intelligent job scheduling

```yaml
# Configure a WBS coordinator agent
agents:
  - id: "project_coordinator"
    name: "Project Coordinator"
    provider: ["cli/claude", "cli/gemini", "cli/copilot"]
    skills:
      include:
        - wbs  # Enable WBS task decomposition skill
    inline:
      type: "agent"
      prompt: |
        You are a project coordinator. Use the WBS skill to decompose 
        complex tasks into 30-minute jobs and assign them to appropriate worker agents.

# Worker agents for task execution
  - id: "frontend_dev"
    name: "Frontend Developer"
    inline:
      type: "agent"
      provider: "cli/copilot"
      prompt: "You specialize in React and frontend development."

  - id: "backend_dev"
    name: "Backend Developer"
    inline:
      type: "agent"
      provider: "cli/claude"
      prompt: "You specialize in API design and backend implementation."

  - id: "tester"
    name: "QA Tester"
    inline:
      type: "agent"
      provider: "cli/gemini"
      prompt: "You specialize in testing and quality assurance."
```

#### 30-Minute Timeboxing Principle

WBS follows strict timeboxing to optimize AI agent performance:

| Category | Duration | Description |
|----------|----------|-------------|
| **Minimum** | 15 min | Below this ‚Üí combine with related tasks |
| **Optimal** | 25-30 min | Target duration for focused AI work |
| **Maximum** | 45 min | Above this ‚Üí re-decompose into smaller jobs |

**Why 30-minute sessions?**
- **Context Management** - Prevents "Lost in the Middle" and context rot in LLMs
- **Focus Optimization** - Matches human Pomodoro technique for sustained attention
- **Quality Assurance** - Smaller tasks yield more accurate results
- **Parallelization** - Enables efficient multi-agent coordination

#### Workflow Example

```bash
# 1. Coordinator analyzes and decomposes the task
crewx query "@project_coordinator Plan and implement user authentication system"

# 2. Coordinator creates WBS jobs:
# - Job 1: Design auth architecture (@backend_dev, 30 min)
# - Job 2: Implement login API (@backend_dev, 30 min)  
# - Job 3: Create login UI components (@frontend_dev, 30 min)
# - Job 4: Write authentication tests (@tester, 30 min)
# - Job 5: Integrate and verify system (@project_coordinator, 30 min)

# 3. Execute jobs sequentially or in parallel
crewx execute "@backend_dev implement OAuth2 authentication flow"
crewx execute "@frontend_dev create React login components"

# 4. Monitor project status
crewx query "@project_coordinator Show WBS project status"
```

#### Project Status Management

```bash
# List all WBS projects
node skills/wbs/wbs.js list

# Show detailed project status
node skills/wbs/wbs.js status <project-id>

# Execute next pending job automatically
node skills/wbs/wbs.js job next <project-id>

# Run all pending jobs sequentially
node skills/wbs/wbs.js job run <project-id>
```

#### Job Status Flow

```
pending ‚Üí running ‚Üí completed
                  ‚Üí failed (retry available)
```

**Key Design Principles:**
1. **AI Makes Intelligent Decisions** - Complexity analysis and task decomposition
2. **Code Handles State Only** - WBS system manages job tracking and execution
3. **30-Minute Sessions** - Optimal duration for AI agent focus and accuracy
4. **Progressive Improvement** - Start simple, iterate based on results

üëâ **[WBS Skill Details ‚Üí](./skills/wbs/SKILL.md)** | **[WBS Skill Examples ‚Üí](./wbs/)**

### Other Benefits
- **No additional costs** - Use existing Claude Pro, Gemini, Codex or GitHub Copilot subscriptions
- **Multi-agent collaboration** - Different AI models working on specialized tasks
- **Parallel execution** - Multiple agents working simultaneously
- **Flexible integration** - CLI, MCP server, or Slack bot

## Requirements

- **Node.js** >= 20.19.0

## Quick Start

### üöÄ One-Command Setup (Recommended)
```bash
# Interactive setup - creates crewx.yaml and helps with Slack setup
npx crewx-quickstart
```

### üì¶ Manual Installation
```bash
# Install
npm install -g crewx

# Initialize
crewx init

# Check system
crewx doctor

# Try it out
crewx query "@claude analyze my code"
crewx execute "@claude create a login component"
```

## Three Ways to Use

### Slack Mode - Team Collaboration (Recommended)
```bash
# Start CrewX in your Slack workspace (read-only query mode)
crewx slack

# Allow agents to run execute tasks (file changes, migrations, etc.)
crewx slack --mode execute

# Your team can now:
# - @mention AI agents in channels
# - Maintain context in threads
# - Share AI insights with the whole team
```
üëâ **[Complete Slack Setup Guide ‚Üí](./SLACK_INSTALL.md)**

### CLI Mode - Direct terminal usage
```bash
crewx query "@claude review this code"
crewx execute "@gemini optimize performance"
crewx query "@claude @gemini @copilot compare approaches"
```

### MCP Server Mode - IDE integration
```bash
crewx mcp  # VS Code, Claude Desktop, Cursor
```

## Supported AI Tools

### CLI Providers (Local)
- **Claude Code** - Advanced reasoning and analysis
- **Gemini CLI** - Real-time web access
- **GitHub Copilot CLI** - Specialized coding assistant
- **Codex CLI** - Open inference with workspace-aware execution

### API Providers (Cloud & Local)
CrewX supports unified HTTP-based API providers with tool calling:

- **Ollama** (`api/ollama`)
- **OpenRouter** (`api/openai`)
- **LiteLLM** (`api/litellm`) - Planned
- **OpenAI** (`api/openai`) - Planned
- **Anthropic** (`api/anthropic`) - Planned
- **Google** (`api/google`) - Planned
- **AWS Bedrock** (`api/bedrock`) - Planned
- **SowonAI** (`api/sowonai`) - Planned

**Quick Start with API Provider:**

```yaml
# crewx.yaml
agents:
  - id: "api_assistant"
    name: "API-based Assistant"
    inline:
      type: "agent"
      provider: "api/anthropic"
      model: "claude-sonnet-4-5-20250929"
      temperature: 0.7
      options:
        query:
          tools: ["read_file", "grep", "find", "glob", "tree"]
        execute:
          tools: ["read_file", "write_file", "replace", "grep", "run_shell_command"]
      prompt: |
        You are an AI assistant with tool calling support.
```

**Key Features:**
- **Tool Calling** - Built-in tools (file operations, shell commands) + custom tools
- **MCP Integration** - Model Context Protocol for external services
- **Mode-based Filtering** - Different tool sets for query vs execute modes
- **Runtime Model Override** - Change models dynamically per request

üìö **[Complete API Provider Guide ‚Üí](./docs/api-provider-guide.md)**

## Basic Usage

```bash
# Read-only analysis
crewx query "@claude explain this function"

# File creation/modification
crewx execute "@claude implement user authentication"

# Parallel tasks
crewx execute "@claude create tests" "@gemini write docs"

# Pipeline workflows
crewx query "@architect design API" | \
crewx execute "@backend implement it"

# Thread-based conversations
crewx query "@claude design login" --thread "auth-feature"
crewx execute "@gemini implement it" --thread "auth-feature"

# Codex CLI agent
crewx query "@codex draft a release checklist"
```

Built-in CLI providers:

- `cli/claude`
- `cli/gemini`
- `cli/copilot`
- `cli/codex`

## Create Custom Agents

```bash
# Let SowonAI CrewX create agents for you
crewx execute "@crewx Create a Python expert agent"
crewx execute "@crewx Create a React specialist with TypeScript"
crewx execute "@crewx Create a DevOps agent for Docker"

# Test your new agent
crewx query "@python_expert Review my code"
```

## Agent Configuration

Create `crewx.yaml` (or `agents.yaml` for backward compatibility):

```yaml
agents:
  - id: "frontend_dev"
    name: "React Expert"
    working_directory: "./src"
    inline:
      type: "agent"
      provider: "cli/claude"  # Built-in CLI provider
      prompt: |
        You are a senior React developer.
        Provide detailed examples and best practices.
```

> **Note:** `crewx.yaml` is the preferred configuration file name. The legacy `agents.yaml` is still supported for backward compatibility. If both files exist, `crewx.yaml` takes priority.

## Layout System

CrewX layouts provide reusable prompt templates that separate structure from content.

### Quick Example

```yaml
# crewx.yaml
agents:
  - id: full_agent
    inline:
      layout: "crewx/default"  # Full agent profile
      prompt: |
        You are a comprehensive assistant.

  - id: simple_agent
    inline:
      layout: "crewx/minimal"  # Lightweight wrapper
      prompt: |
        You are a simple assistant.
```

**Features:**
- üé® **Reusable Templates** - Share layouts across agents
- ‚öõÔ∏è **Props Schema** - React PropTypes-style validation for custom layouts
- üîß **Built-in Layouts** - `crewx/default`, `crewx/minimal`
- üõ°Ô∏è **Security Containers** - Automatic prompt wrapping

üëâ **[Layout System Guide ‚Üí](./docs/layouts.md)** for detailed usage

## Remote Agents (Experimental)

Connect to other CrewX instances and delegate tasks across projects or servers.

**Quick Example:**
```bash
# Add a remote CrewX instance
providers:
  - id: backend_server
    type: remote
    location: "http://api.example.com:3000"
    external_agent_id: "backend_team"

agents:
  - id: "remote_backend"
    provider: "remote/backend_server"

# Use it like any other agent
crewx query "@remote_backend check API status"
```

**Use Cases:**
- **Project isolation** - Separate configurations for different codebases
- **Distributed teams** - Each team runs their own CrewX with specialized agents
- **Resource sharing** - Access powerful compute resources remotely
- **Multi-project coordination** - Orchestrate work across multiple projects

üëâ **[Remote Agents Guide ‚Üí](./docs/remote-agents.md)** for detailed setup and configuration

## Monorepo Architecture

SowonAI CrewX is structured as a monorepo with separate packages for maximum flexibility:

```
crewx/
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ sdk/          # @sowonai/crewx-sdk (Apache-2.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Core AI provider interfaces
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Conversation management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Knowledge utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Agent domain types
‚îÇ   ‚îî‚îÄ‚îÄ cli/          # crewx (MIT)
‚îÇ       ‚îú‚îÄ‚îÄ CLI implementation
‚îÇ       ‚îú‚îÄ‚îÄ Slack integration
‚îÇ       ‚îú‚îÄ‚îÄ MCP server
‚îÇ       ‚îî‚îÄ‚îÄ Provider implementations
‚îú‚îÄ‚îÄ docs/             # Comprehensive documentation
‚îî‚îÄ‚îÄ README.md         # This file
```

### Package Overview

| Package | License | Description | Install |
|---------|---------|-------------|---------|
| `@sowonai/crewx-sdk` | Apache-2.0 | Core SDK for building custom AI integrations | `npm install @sowonai/crewx-sdk` |
| `crewx` | MIT | Full-featured CLI tool for immediate use | `npm install -g crewx` |

**When to use what:**
- **Use `crewx` CLI** if you want to use AI agents immediately in your terminal, Slack, or IDE
- **Use `@sowonai/crewx-sdk`** if you're building custom AI tools or integrating SowonAI CrewX into your application

### SDK/CLI Integration

The SDK provides reusable components that power the CLI, enabling custom integrations:

**SDK Provides:**
- `BaseMessageFormatter` - Platform-agnostic message formatting
- `BaseAIProvider` - Extensible AI provider base class
- Built-in providers: `ClaudeProvider`, `GeminiProvider`, `CopilotProvider`, `CodexProvider`
- `RemoteAgentManager` - Remote agent communication
- `createCrewxAgent` - High-level agent factory API
- `TemplateContext` - Cross-platform template context interface
- `AgentMetadata` - Agent capabilities and specialties metadata

**CLI Adds:**
- NestJS integration and dependency injection
- Slack-specific formatting and bot features
- MCP server implementation
- File system operations and tool execution
- Platform-specific security and authentication

**Example - Using SDK Directly:**
```typescript
import { ClaudeProvider, RemoteAgentManager } from '@sowonai/crewx-sdk';

// Use SDK providers without CLI
const provider = new ClaudeProvider({
  apiKey: process.env.ANTHROPIC_API_KEY,
  logger: console,
});

const result = await provider.query('Analyze codebase');
```

### Development

```bash
# Install dependencies
npm install

# Build all packages
npm run build

# Run tests
npm test

# Build specific package
npm run build --workspace @sowonai/crewx-sdk
npm run build --workspace crewx
```

For more information, see:
- [SDK Development Guide](packages/sdk/README.md)
- [CLI Development Guide](packages/cli/README.md)
- [Build & Release Guide](BUILD.md)

## Documentation

### User Guides
- [üöÄ API Provider Guide](docs/api-provider-guide.md) - **NEW!** Complete guide for API providers (OpenAI, Anthropic, Google, Bedrock, LiteLLM, Ollama, SowonAI)
- [üìñ CLI Guide](docs/cli-guide.md) - Complete CLI reference
- [üîå MCP Integration](docs/mcp-integration.md) - IDE setup and MCP servers
- [‚öôÔ∏è Agent Configuration](docs/agent-configuration.md) - Custom agents and advanced config
- [üåê Remote Agents](docs/remote-agents.md) - Connect to remote CrewX instances
- [üìö Template System](docs/templates.md) - Knowledge management and dynamic prompts for agents
- [üìù Template Variables](docs/template-variables.md) - Dynamic variables in agent configurations and TemplateContext usage
- [üé® Layout System](docs/layouts.md) - Reusable prompt templates with React PropTypes-style props
- [üîß Troubleshooting](docs/troubleshooting.md) - Common issues and solutions
- [üí¨ Slack Integration](SLACK_INSTALL.md) - Slack bot setup

### Developer Guides
- [üèóÔ∏è SDK API Reference](packages/sdk/README.md) - Build custom integrations
- [‚öôÔ∏è CLI Development](packages/cli/README.md) - CLI architecture and development
- [üì¶ Build & Release](BUILD.md) - Building and releasing packages
- [üîß Development Workflow](docs/development.md) - Contributing guidelines
- [üß© Context Integration Standard](packages/docs/context-integration-standard.md) - TemplateContext pipeline and layout responsibilities
- [üõ†Ô∏è Context Migration Guide](packages/docs/context-integration-migration.md) - Upgrade steps for custom agents

## License

- **SDK** (`@sowonai/crewx-sdk`): Apache-2.0 License
- **CLI** (`crewx`): MIT License

Copyright (c) 2025 SowonLabs

## Contributing

We welcome contributions! Please read our [Contributing Guide](CONTRIBUTING.md) before submitting pull requests.

For SDK contributions, please sign our [Contributor License Agreement (CLA)](docs/CLA.md).

---

Built by [SowonLabs](https://github.com/sowonlabs)
