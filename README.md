# SowonAI CrewX

> Bring Your Own AI(BYOA) team in Slack/IDE(MCP) with your existing subscriptions
Transform Claude, Gemini, Codex and Copilot into a collaborative development team. No extra costsâ€”just your existing AI subscriptions working together.

![CrewX usage overview](docs/diagram1.svg)

## Why CrewX?

### **Slack Team Collaboration** - Your AI Team in Slack
Bring AI agents directly into your team's workspace:
- **Team-wide AI access** - Everyone benefits from AI expertise in Slack channels
- **Thread-based context** - Maintains conversation history automatically
- **Multi-agent collaboration** - `@claude`, `@gemini`, `@copilot` work together in real-time
- **Natural integration** - Works like chatting with team members
- **Shared knowledge** - Team learns from AI interactions, not isolated sessions

### **Remote Agents** - Distributed AI Teams (Experimental)
Connect and orchestrate CrewX instances across projects and servers:
- **Cross-project experts** - Frontend dev asks backend team's API specialist agent
- **Team collaboration** - Each team builds their own agents, entire org can use them
- **Expert knowledge sharing** - Ask senior's code review agent, security team's audit agent anytime
- **Separate but connected** - Each project keeps its own context, collaborate when needed

```yaml
# Access another project's specialized agents
providers:
  - id: backend_project
    type: remote
    location: "file:///workspace/backend-api/crewx.yaml"
    external_agent_id: "api_expert"

# Use their expertise in your project
crewx query "@api_expert design user authentication API"
crewx execute "@api_expert implement OAuth flow"
```

### **Plugin Provider System** - Universal AI Integration
Transform any CLI tool or AI service into an agent:
- **Bring Your Own AI** - OpenAI, Anthropic, Ollama, LiteLLM, or any AI service
- **Bring Your Own Tools** - jq, curl, ffmpeg, or any CLI tool becomes an agent
- **Bring Your Own Framework** - Integrate LangChain, CrewAI, AutoGPT seamlessly
- **No coding required** - Simple YAML configuration
- **Mix and match** - Combine different AI services in one workflow

```yaml
# Example: Add any AI service as a plugin
providers:
  - id: ollama
    type: plugin
    cli_command: ollama
    default_model: "llama3"
    query_args: ["run", "{model}"]
    prompt_in_args: false

agents:
  - id: "local_llama"
    provider: "plugin/ollama"
```

### **Claude Skills Compatible** - Reusable AI Expertise
Share and reuse specialized AI capabilities using Claude Code skills format:
- **100% Claude Code compatible** - Use existing Claude skills without modification
- **Agent enhancement** - Add specialized capabilities to any agent
- **Progressive disclosure** - Skills load metadata first, content on-demand
- **Cross-agent sharing** - One skill, multiple agents
- **Simple YAML + Markdown** - Easy to create and maintain

```yaml
# Enable skills for your agents
skills:
  paths:
    - ./skills                    # Custom skill directories
  include:
    - hello                       # Specific skills to load
    - code-reviewer
    - api-designer

agents:
  - id: "senior_dev"
    provider: "cli/claude"
    skills:
      include:
        - code-reviewer           # Agent-specific skills
        - api-designer
    inline:
      prompt: |
        You are a senior developer with specialized skills.
```

**Create a skill** in `skills/hello/SKILL.md`:
```markdown
---
name: hello
description: Friendly greeting skill
version: 0.0.1
---

# Hello Skill

Use this skill to provide friendly greetings.

## Capabilities
- Generate personalized greetings
- Demonstrate skill system functionality
```

**Test across providers**:
```bash
# Test with different AI providers
CREWX_CONFIG=crewx.skills.yaml crewx query "@skill_tester_claude test hello skill"
CREWX_CONFIG=crewx.skills.yaml crewx query "@skill_tester_gemini test hello skill"
```

ğŸ‘‰ **[Skills Documentation â†’](./docs/skills.md)** | **[Example Skills â†’](./skills/)**

### **Project Templates** - Quick Project Bootstrap
Start new projects with pre-configured templates:
- **Ready-to-use setups** - WBS automation, development workflows, deployment configs
- **Git-based templates** - Templates stored in GitHub repository
- **Simple commands** - List, preview, and initialize templates instantly
- **Customizable** - Edit downloaded templates to fit your needs

```bash
# List available templates
crewx template list

# View template details
crewx template show wbs-automation

# Initialize template in current directory
crewx template init wbs-automation
```

**Available templates:**
- `wbs-automation` - WBS task tracking with coordinator agent
- `development` - Development team setup with code review agents
- `deployment` - CI/CD deployment automation
- More templates coming soon!

ğŸ‘‰ **[Project Templates Documentation â†’](./docs/project-templates.md)**

### Other Benefits
- **No additional costs** - Use existing Claude Pro, Gemini, Codex or GitHub Copilot subscriptions
- **Multi-agent collaboration** - Different AI models working on specialized tasks
- **Parallel execution** - Multiple agents working simultaneously
- **Flexible integration** - CLI, MCP server, or Slack bot

## Requirements

- **Node.js** >= 20.19.0

## Quick Start

### ğŸš€ One-Command Setup (Recommended)
```bash
# Interactive setup - creates crewx.yaml and helps with Slack setup
npx crewx-quickstart
```

### ğŸ“¦ Manual Installation
```bash
# Install
npm install -g crewx

# Initialize
crewx init

# Check system
crewx doctor

# Try it out
crewx query "@claude analyze my code"
crewx execute "@claude create a login component"
```

## Three Ways to Use

### Slack Mode - Team Collaboration (Recommended)
```bash
# Start CrewX in your Slack workspace (read-only query mode)
crewx slack

# Allow agents to run execute tasks (file changes, migrations, etc.)
crewx slack --mode execute

# Your team can now:
# - @mention AI agents in channels
# - Maintain context in threads
# - Share AI insights with the whole team
```
ğŸ‘‰ **[Complete Slack Setup Guide â†’](./SLACK_INSTALL.md)**

### CLI Mode - Direct terminal usage
```bash
crewx query "@claude review this code"
crewx execute "@gemini optimize performance"
crewx query "@claude @gemini @copilot compare approaches"
```

### MCP Server Mode - IDE integration
```bash
crewx mcp  # VS Code, Claude Desktop, Cursor
```

## Supported AI Tools

### CLI Providers (Local)
- **Claude Code** - Advanced reasoning and analysis
- **Gemini CLI** - Real-time web access
- **GitHub Copilot CLI** - Specialized coding assistant
- **Codex CLI** - Open inference with workspace-aware execution

### API Providers (Cloud & Local)
CrewX supports unified HTTP-based API providers with tool calling:

- **Ollama** (`api/ollama`)
- **OpenRouter** (`api/openai`)
- **LiteLLM** (`api/litellm`) - Planned
- **OpenAI** (`api/openai`) - Planned
- **Anthropic** (`api/anthropic`) - Planned
- **Google** (`api/google`) - Planned
- **AWS Bedrock** (`api/bedrock`) - Planned
- **SowonAI** (`api/sowonai`) - Planned

**Quick Start with API Provider:**

```yaml
# crewx.yaml
agents:
  - id: "api_assistant"
    name: "API-based Assistant"
    inline:
      type: "agent"
      provider: "api/anthropic"
      model: "claude-sonnet-4-5-20250929"
      temperature: 0.7
      options:
        query:
          tools: ["read_file", "grep", "find", "glob", "tree"]
        execute:
          tools: ["read_file", "write_file", "replace", "grep", "run_shell_command"]
      prompt: |
        You are an AI assistant with tool calling support.
```

**Key Features:**
- **Tool Calling** - Built-in tools (file operations, shell commands) + custom tools
- **MCP Integration** - Model Context Protocol for external services
- **Mode-based Filtering** - Different tool sets for query vs execute modes
- **Runtime Model Override** - Change models dynamically per request

ğŸ“š **[Complete API Provider Guide â†’](./docs/api-provider-guide.md)**

## Basic Usage

```bash
# Read-only analysis
crewx query "@claude explain this function"

# File creation/modification
crewx execute "@claude implement user authentication"

# Parallel tasks
crewx execute "@claude create tests" "@gemini write docs"

# Pipeline workflows
crewx query "@architect design API" | \
crewx execute "@backend implement it"

# Thread-based conversations
crewx query "@claude design login" --thread "auth-feature"
crewx execute "@gemini implement it" --thread "auth-feature"

# Codex CLI agent
crewx query "@codex draft a release checklist"
```

Built-in CLI providers:

- `cli/claude`
- `cli/gemini`
- `cli/copilot`
- `cli/codex`

## Create Custom Agents

```bash
# Let SowonAI CrewX create agents for you
crewx execute "@crewx Create a Python expert agent"
crewx execute "@crewx Create a React specialist with TypeScript"
crewx execute "@crewx Create a DevOps agent for Docker"

# Test your new agent
crewx query "@python_expert Review my code"
```

## Agent Configuration

Create `crewx.yaml` (or `agents.yaml` for backward compatibility):

```yaml
agents:
  - id: "frontend_dev"
    name: "React Expert"
    working_directory: "./src"
    inline:
      type: "agent"
      provider: "cli/claude"  # Built-in CLI provider
      prompt: |
        You are a senior React developer.
        Provide detailed examples and best practices.
```

> **Note:** `crewx.yaml` is the preferred configuration file name. The legacy `agents.yaml` is still supported for backward compatibility. If both files exist, `crewx.yaml` takes priority.

## Layout System

CrewX layouts provide reusable prompt templates that separate structure from content.

### Quick Example

```yaml
# crewx.yaml
agents:
  - id: full_agent
    inline:
      layout: "crewx/default"  # Full agent profile
      prompt: |
        You are a comprehensive assistant.

  - id: simple_agent
    inline:
      layout: "crewx/minimal"  # Lightweight wrapper
      prompt: |
        You are a simple assistant.
```

**Features:**
- ğŸ¨ **Reusable Templates** - Share layouts across agents
- âš›ï¸ **Props Schema** - React PropTypes-style validation for custom layouts
- ğŸ”§ **Built-in Layouts** - `crewx/default`, `crewx/minimal`
- ğŸ›¡ï¸ **Security Containers** - Automatic prompt wrapping

ğŸ‘‰ **[Layout System Guide â†’](./docs/layouts.md)** for detailed usage

## Remote Agents (Experimental)

Connect to other CrewX instances and delegate tasks across projects or servers.

**Quick Example:**
```bash
# Add a remote CrewX instance
providers:
  - id: backend_server
    type: remote
    location: "http://api.example.com:3000"
    external_agent_id: "backend_team"

agents:
  - id: "remote_backend"
    provider: "remote/backend_server"

# Use it like any other agent
crewx query "@remote_backend check API status"
```

**Use Cases:**
- **Project isolation** - Separate configurations for different codebases
- **Distributed teams** - Each team runs their own CrewX with specialized agents
- **Resource sharing** - Access powerful compute resources remotely
- **Multi-project coordination** - Orchestrate work across multiple projects

ğŸ‘‰ **[Remote Agents Guide â†’](./docs/remote-agents.md)** for detailed setup and configuration

## Monorepo Architecture

SowonAI CrewX is structured as a monorepo with separate packages for maximum flexibility:

```
crewx/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ sdk/          # @sowonai/crewx-sdk (Apache-2.0)
â”‚   â”‚   â”œâ”€â”€ Core AI provider interfaces
â”‚   â”‚   â”œâ”€â”€ Conversation management
â”‚   â”‚   â”œâ”€â”€ Knowledge utilities
â”‚   â”‚   â””â”€â”€ Agent domain types
â”‚   â””â”€â”€ cli/          # crewx (MIT)
â”‚       â”œâ”€â”€ CLI implementation
â”‚       â”œâ”€â”€ Slack integration
â”‚       â”œâ”€â”€ MCP server
â”‚       â””â”€â”€ Provider implementations
â”œâ”€â”€ docs/             # Comprehensive documentation
â””â”€â”€ README.md         # This file
```

### Package Overview

| Package | License | Description | Install |
|---------|---------|-------------|---------|
| `@sowonai/crewx-sdk` | Apache-2.0 | Core SDK for building custom AI integrations | `npm install @sowonai/crewx-sdk` |
| `crewx` | MIT | Full-featured CLI tool for immediate use | `npm install -g crewx` |

**When to use what:**
- **Use `crewx` CLI** if you want to use AI agents immediately in your terminal, Slack, or IDE
- **Use `@sowonai/crewx-sdk`** if you're building custom AI tools or integrating SowonAI CrewX into your application

### SDK/CLI Integration

The SDK provides reusable components that power the CLI, enabling custom integrations:

**SDK Provides:**
- `BaseMessageFormatter` - Platform-agnostic message formatting
- `BaseAIProvider` - Extensible AI provider base class
- Built-in providers: `ClaudeProvider`, `GeminiProvider`, `CopilotProvider`, `CodexProvider`
- `RemoteAgentManager` - Remote agent communication
- `createCrewxAgent` - High-level agent factory API
- `TemplateContext` - Cross-platform template context interface
- `AgentMetadata` - Agent capabilities and specialties metadata

**CLI Adds:**
- NestJS integration and dependency injection
- Slack-specific formatting and bot features
- MCP server implementation
- File system operations and tool execution
- Platform-specific security and authentication

**Example - Using SDK Directly:**
```typescript
import { ClaudeProvider, RemoteAgentManager } from '@sowonai/crewx-sdk';

// Use SDK providers without CLI
const provider = new ClaudeProvider({
  apiKey: process.env.ANTHROPIC_API_KEY,
  logger: console,
});

const result = await provider.query('Analyze codebase');
```

### Development

```bash
# Install dependencies
npm install

# Build all packages
npm run build

# Run tests
npm test

# Build specific package
npm run build --workspace @sowonai/crewx-sdk
npm run build --workspace crewx
```

For more information, see:
- [SDK Development Guide](packages/sdk/README.md)
- [CLI Development Guide](packages/cli/README.md)
- [Build & Release Guide](BUILD.md)

## Documentation

### User Guides
- [ğŸš€ API Provider Guide](docs/api-provider-guide.md) - **NEW!** Complete guide for API providers (OpenAI, Anthropic, Google, Bedrock, LiteLLM, Ollama, SowonAI)
- [ğŸ“– CLI Guide](docs/cli-guide.md) - Complete CLI reference
- [ğŸ”Œ MCP Integration](docs/mcp-integration.md) - IDE setup and MCP servers
- [âš™ï¸ Agent Configuration](docs/agent-configuration.md) - Custom agents and advanced config
- [ğŸŒ Remote Agents](docs/remote-agents.md) - Connect to remote CrewX instances
- [ğŸ“š Template System](docs/templates.md) - Knowledge management and dynamic prompts for agents
- [ğŸ“ Template Variables](docs/template-variables.md) - Dynamic variables in agent configurations and TemplateContext usage
- [ğŸ¨ Layout System](docs/layouts.md) - Reusable prompt templates with React PropTypes-style props
- [ğŸ”§ Troubleshooting](docs/troubleshooting.md) - Common issues and solutions
- [ğŸ’¬ Slack Integration](SLACK_INSTALL.md) - Slack bot setup

### Developer Guides
- [ğŸ—ï¸ SDK API Reference](packages/sdk/README.md) - Build custom integrations
- [âš™ï¸ CLI Development](packages/cli/README.md) - CLI architecture and development
- [ğŸ“¦ Build & Release](BUILD.md) - Building and releasing packages
- [ğŸ”§ Development Workflow](docs/development.md) - Contributing guidelines
- [ğŸ§© Context Integration Standard](packages/docs/context-integration-standard.md) - TemplateContext pipeline and layout responsibilities
- [ğŸ› ï¸ Context Migration Guide](packages/docs/context-integration-migration.md) - Upgrade steps for custom agents

## License

- **SDK** (`@sowonai/crewx-sdk`): Apache-2.0 License
- **CLI** (`crewx`): MIT License

Copyright (c) 2025 SowonLabs

## Contributing

We welcome contributions! Please read our [Contributing Guide](CONTRIBUTING.md) before submitting pull requests.

For SDK contributions, please sign our [Contributor License Agreement (CLA)](docs/CLA.md).

---

Built by [SowonLabs](https://github.com/sowonlabs)

<!-- WBS test -->
